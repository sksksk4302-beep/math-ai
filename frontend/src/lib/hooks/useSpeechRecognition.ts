import { useState, useCallback, useRef, useEffect } from 'react';
import { normalizeKoreanNumber } from '../utils/korean';

interface UseSpeechRecognitionProps {
    onResult: (number: string) => void;
}

export const useSpeechRecognition = ({ onResult }: UseSpeechRecognitionProps) => {
    const [isListening, setIsListening] = useState(false);
    const recognitionRef = useRef<any>(null);
    const isStartingRef = useRef(false);

    const startListening = useCallback(() => {
        // Ï§ëÎ≥µ Ìò∏Ï∂ú Î∞©ÏßÄ
        if (isListening || isStartingRef.current) {
            console.log("‚ö†Ô∏è [STT] Already listening or starting, skipping");
            return;
        }

        if (!('webkitSpeechRecognition' in window)) {
            console.warn("‚ùå Browser does not support speech recognition");
            return;
        }

        isStartingRef.current = true;

        // Ïù¥Ï†Ñ Ïù∏Ïä§ÌÑ¥Ïä§ ÏôÑÏ†ÑÌûà Ï†ïÎ¶¨ (Zombie Instance Î∞©ÏßÄ)
        if (recognitionRef.current) {
            console.log("üßπ [STT] Cleaning up previous instance");
            try {
                recognitionRef.current.abort();
            } catch (e) {
                console.warn("‚ö†Ô∏è [STT] Abort failed:", e);
            }
            recognitionRef.current = null;
        }

        // ÏÉà Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±
        const recognition = new (window as any).webkitSpeechRecognition();
        recognition.lang = 'ko-KR';
        recognition.continuous = false;
        recognition.interimResults = false;

        recognition.onstart = () => {
            console.log("‚úÖ [STT] Recognition started");
            setIsListening(true);
            isStartingRef.current = false;
        };

        recognition.onend = () => {
            console.log("üîö [STT] Recognition ended");
            setIsListening(false);
            isStartingRef.current = false;
        };

        recognition.onresult = (event: any) => {
            const transcript = event.results[0][0].transcript;
            console.log("üó£Ô∏è [STT] Recognized speech:", transcript);
            const number = normalizeKoreanNumber(transcript);
            console.log("üî¢ [STT] Normalized to number:", number);
            if (number) {
                onResult(number);
            }
        };

        recognition.onerror = (event: any) => {
            console.error("‚ùå [STT] Speech error:", event.error);
            setIsListening(false);
            isStartingRef.current = false;
            if (event.error === 'not-allowed') {
                alert("ÎßàÏù¥ÌÅ¨ Í∂åÌïúÏù¥ Ï∞®Îã®ÎêòÏóàÏäµÎãàÎã§. Ï£ºÏÜåÏ∞Ω ÏòÜ ÏÑ§Ï†ïÏóêÏÑú ÌóàÏö©Ìï¥Ï£ºÏÑ∏Ïöî.");
            }
        };

        recognitionRef.current = recognition;

        try {
            recognition.start();
            console.log("‚ñ∂Ô∏è [STT] Recognition.start() called");
        } catch (e) {
            console.error("‚ùå [STT] Start failed:", e);
            setIsListening(false);
            isStartingRef.current = false;
            recognitionRef.current = null;
        }
    }, [isListening, onResult]);

    const stopListening = useCallback(() => {
        console.log("üõë [STT] stopListening called");
        if (recognitionRef.current) {
            try {
                recognitionRef.current.stop();
            } catch (e) {
                console.warn("‚ö†Ô∏è [STT] Stop failed:", e);
            }
        }
        setIsListening(false);
        isStartingRef.current = false;
    }, []);

    // Cleanup on unmount
    useEffect(() => {
        return () => {
            if (recognitionRef.current) {
                console.log("üßπ [STT] Cleanup on unmount");
                try {
                    recognitionRef.current.abort();
                } catch (e) {
                    console.warn("‚ö†Ô∏è [STT] Cleanup abort failed:", e);
                }
            }
        };
    }, []);

    return {
        isListening,
        startListening,
        stopListening,
    };
};
