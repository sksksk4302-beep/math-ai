import { useState, useCallback, useRef, useEffect } from 'react';
import { normalizeKoreanNumber } from '../utils/korean';

interface UseSpeechRecognitionProps {
    onResult: (number: string) => void;
}

export const useSpeechRecognition = ({ onResult }: UseSpeechRecognitionProps) => {
    const [isListening, setIsListening] = useState(false);
    const recognitionRef = useRef<any>(null);
    const onResultRef = useRef(onResult);

    // âœ… ì‚¬ìš©ìê°€ 'ë“£ê¸°'ë¥¼ ì›í•˜ëŠ”ì§€ ì—¬ë¶€ (ì‹¤ì œ ë§ˆì´í¬ ìƒíƒœì™€ ë³„ê°œ)
    // ì´ ê°’ì´ trueì¸ ë™ì•ˆì—ëŠ” ë§ˆì´í¬ê°€ êº¼ì§€ë©´ ë¬´ì¡°ê±´ ë‹¤ì‹œ ì¼­ë‹ˆë‹¤.
    const shouldListenRef = useRef(false);

    useEffect(() => {
        onResultRef.current = onResult;
    }, [onResult]);

    // startRecognitionì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬ (onend í•¸ë“¤ëŸ¬ì—ì„œ ì¬í˜¸ì¶œ ê°€ëŠ¥í•˜ë„ë¡)
    const startRecognition = () => {
        if (!('webkitSpeechRecognition' in window)) {
            console.warn("âŒ Browser does not support speech recognition");
            return;
        }

        const recognition = new (window as any).webkitSpeechRecognition();
        recognitionRef.current = recognition;

        recognition.lang = 'ko-KR';
        recognition.continuous = true;  // âœ… ì§€ì†ì ìœ¼ë¡œ ìŒì„± ë“£ê¸°
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;

        recognition.onstart = () => {
            console.log("âœ… [STT] Recognition started");
            setIsListening(true);
        };

        recognition.onend = () => {
            console.log("ğŸ”š [STT] Recognition ended, shouldListen:", shouldListenRef.current);
            setIsListening(false);

            // âœ… recognitionRefë¥¼ ë¨¼ì € nullë¡œ ì„¤ì • (ì¬ì‹œì‘ ì¡°ê±´ì´ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ë„ë¡)
            const shouldRestart = shouldListenRef.current;
            recognitionRef.current = null;

            // ëª¨ë°”ì¼/PC ëŠê¹€ ë°©ì§€: ì‚¬ìš©ìê°€ ë©ˆì¶”ì§€ ì•Šì•˜ëŠ”ë° êº¼ì¡Œë‹¤ë©´ ì¬ì‹œì‘
            if (shouldRestart) {
                console.log("ğŸ”„ [STT] Attempting auto-restart...");
                setTimeout(() => {
                    if (shouldListenRef.current) {
                        startRecognition();
                    }
                }, 100);
            }
        };

        recognition.onresult = (event: any) => {
            const transcript = event.results[0][0].transcript;
            console.log("ğŸ—£ï¸ [STT] Recognized speech:", transcript);
            const number = normalizeKoreanNumber(transcript);
            console.log("ğŸ”¢ [STT] Normalized to number:", number);
            if (number) {
                onResultRef.current(number);
            }
        };

        recognition.onerror = (event: any) => {
            console.error("âŒ [STT] Speech error:", event.error);
            // 'not-allowed'ëŠ” ê¶Œí•œ ê±°ë¶€ì´ë¯€ë¡œ ì¬ì‹œì‘í•˜ë©´ ì•ˆë¨ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
            if (event.error === 'not-allowed') {
                shouldListenRef.current = false;
                setIsListening(false);
                alert("ë§ˆì´í¬ ê¶Œí•œì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ì†Œì°½ ì˜† ì„¤ì •ì—ì„œ í—ˆìš©í•´ì£¼ì„¸ìš”.");
            }
            // ê·¸ ì™¸ ì—ëŸ¬(no-speech ë“±)ëŠ” onendì—ì„œ ì¬ì‹œì‘ë¨
        };

        try {
            recognition.start();
            console.log("â–¶ï¸ [STT] Recognition.start() called");
        } catch (e) {
            console.error("âŒ [STT] Start failed:", e);
        }
    };

    // ë§ˆì´í¬ ì¼œê¸° (iOS í˜¸í™˜)
    const startListening = useCallback(() => {
        console.log("ğŸ¤ [STT] startListening called, current state:", {
            shouldListen: shouldListenRef.current,
            hasRecognition: !!recognitionRef.current,
            isListening
        });

        // âœ… ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆìœ¼ë©´ ë¨¼ì € ì •ë¦¬ (153abfe ë°©ì‹ìœ¼ë¡œ ë³µì›)
        if (recognitionRef.current) {
            try {
                recognitionRef.current.abort();
                console.log("ğŸ›‘ [STT] Aborted previous instance");
            } catch (e) {
                console.warn("âš ï¸ [STT] Abort failed:", e);
            }
            recognitionRef.current = null;
        }

        shouldListenRef.current = true;
        startRecognition();
    }, [isListening]);

    // ë§ˆì´í¬ ë„ê¸° (ëª…ì‹œì  ì¤‘ë‹¨ - ê²Œì„ ëë‚  ë•Œë§Œ í˜¸ì¶œ)
    const stopListening = useCallback(() => {
        shouldListenRef.current = false; // ì¬ì‹œì‘ ë°©ì§€ í”Œë˜ê·¸ ë”
        if (recognitionRef.current) {
            recognitionRef.current.abort();
            recognitionRef.current = null;
        }
        setIsListening(false);
    }, []);

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    useEffect(() => {
        return () => {
            shouldListenRef.current = false;
            if (recognitionRef.current) {
                recognitionRef.current.abort();
            }
        };
    }, []);

    return {
        isListening,
        startListening, // ì´ì œ ì™¸ë¶€ì—ì„œ í•œ ë²ˆë§Œ ë¶€ë¥´ë©´ ë©ë‹ˆë‹¤.
        stopListening,
        isProcessingStt: false // í˜¸í™˜ì„± ìœ ì§€
    };
};
